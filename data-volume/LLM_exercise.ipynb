{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad59e7c8-e469-4777-859e-be21787ad59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Basic Vocab\n",
    "\n",
    "Observations/Instances/Samples:\n",
    "- In machine learning, an observation refers to a single instance of data in a dataset.\n",
    "- Each observation consists of several features and, in supervised learning, a target label.\n",
    "- A sample is a subset of observations/instances in a data set.\n",
    "From: https://deepchecks.com/glossary/observation-ml/\n",
    "\n",
    "# Target Label/Variable/Class\n",
    "- A target is a dataset variable to be predicted by an ML model.\n",
    "  This is the variable that describes the outcome of the process.\n",
    "  Broadly speaking, the terms label, class, and target may be used interchangeably.\n",
    "From https://toloka.ai/blog/machine-learning-labels-and-features/\n",
    "\n",
    "# Supervised vs Unsupervised Learning:\n",
    "This notebook is an exercise in supervised learning to leverage an LLM to\n",
    "determine if a sentence contains gender bias.\n",
    "Further reading: https://www.ibm.com/think/topics/supervised-vs-unsupervised-learning\n",
    "\n",
    "# Paper discussing types of gender bias in language: https://arxiv.org/pdf/2201.08675\n",
    "Datasets originate from:\n",
    "- locally deployed LLama 3 LLM (~554)\n",
    "- https://www.kaggle.com/datasets/dgrosz/sexist-workplace-statements (1138)\n",
    "\n",
    "DistilBERT Refs\n",
    "- https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "226412ef-2013-48e1-8767-9117bd2e6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Hugging Face datasets \n",
    "from datasets import load_from_disk, DatasetDict\n",
    "\n",
    "\"\"\"\n",
    "Open 'aggregate_data.tsv' to inspect the data set.\n",
    "The columns should be self-explanatory, with the exception of 'label':\n",
    "- 0 indicates a lack of societal gender bias.\n",
    "- 1 indicates a presence of societal gender bias.\n",
    "\"\"\"\n",
    "dataset = load_from_disk(\"./dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc06538b-193f-4469-a272-272b73d3ae75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'sentence': \"Gender diversity in parenting styles enriches children's upbringing.\",\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect indidivual example.\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10582088-6a3d-4857-9be6-f43729015aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8705c18560f49739ccc72cfbb4f6656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1691 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PRE-PROCESSING (https://arxiv.org/pdf/2111.03612, pg. 3)\n",
    "- Hyphens and hashtags swap for whitespace\n",
    "- Swap all usernames with string 'username'\n",
    "- Lowercase it all\n",
    "- Purge punctuation\n",
    "\n",
    "Note that removing typical NLP stop words would likely trash our accuracy,\n",
    "given the context they would contain.\n",
    "\"\"\"\n",
    "def preprocess_text(text):\n",
    "    # Replace hyphens with whitespace\n",
    "    text = text.replace('-', ' ')\n",
    "    \n",
    "    # Remove all '#' symbols\n",
    "    text = text.replace('#', '')\n",
    "    \n",
    "    # Replace Twitter usernames (e.g., @username) with the word \"username\"\n",
    "    text = re.sub(r'@\\w+', 'username', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Lowercase all words\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    def preprocess_example(example):\n",
    "        example['sentence'] = preprocess_text(example['sentence'])\n",
    "        return example\n",
    "    \n",
    "    return dataset.map(preprocess_example)\n",
    "\n",
    "dataset = preprocess_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61bfbb4c-8a40-4675-ba42-d24d355298b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'sentence': 'gender diversity in parenting styles enriches childrens upbringing',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect pre-processed example.\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "985b8f0d-5056-446d-add3-bbf7cf9705e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213c59cc802b4f839976122d4827c6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1691 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize dataset. Do not modify this block.\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=False)\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e26a185-e7df-4a25-bcac-4e208b84d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load accuracy metric. Do not modify this block.\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a40dd7b-6233-42fb-b206-91da102a54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mappings. Do not modify this block.\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2531555e-2a01-4caa-8b6d-3ed0983afa4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98147bc40baa4da9b59b41b1b9a3568f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "\"\"\"\n",
    "Load DistilBERT with AutoModelForSequenceClassification along with the number of expected labels,\n",
    "and the label mappings\n",
    "\"\"\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b09cc4a7-b3bb-4192-905f-e4593faa7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test.\n",
    "def split_dataset(dataset, test_size=0.2, seed=42):\n",
    "    \"\"\"\n",
    "    Split the Hugging Face dataset into training and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: Hugging Face dataset obj\n",
    "    - test_size (float): Proportion of the dataset to include in the test split (default is 0.2).\n",
    "    - seed (int): Random seed for reproducibility (default is 42).\n",
    "\n",
    "    Returns:\n",
    "    - DatasetDict: A dictionary with 'train' and 'test' splits.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    train_test_split = dataset.train_test_split(test_size=test_size, seed=seed)\n",
    "    \n",
    "    # Return the DatasetDict with 'train' and 'test' splits\n",
    "    return DatasetDict({\n",
    "        'train': train_test_split['train'],\n",
    "        'test': train_test_split['test']\n",
    "    })\n",
    "\n",
    "# Split the dataset\n",
    "dataset_splits = split_dataset(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6138da40-f088-48fc-8daf-553d7896d9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 02:04, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.214054</td>\n",
       "      <td>0.914454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0.949853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=170, training_loss=0.32378726286046644, metrics={'train_runtime': 125.6308, 'train_samples_per_second': 21.523, 'train_steps_per_second': 1.353, 'total_flos': 21080944614240.0, 'train_loss': 0.32378726286046644, 'epoch': 2.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"model_output_dir\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_splits[\"train\"],\n",
    "    eval_dataset=dataset_splits[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32a7c7c2-d676-4292-9987-7ea9e65b30c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9798781871795654}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inference Time\n",
    "https://huggingface.co/docs/transformers/en/pipeline_tutorial\n",
    "\"\"\"\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "loaded_model = DistilBertForSequenceClassification.from_pretrained(\"model_output_dir\")  # automatically loads the configuration.\n",
    "\n",
    "# sampleText = \"Women belong in the kitchen.\"\n",
    "sampleText = \"Women should be able to choose their profession free from societal bias.\"\n",
    "# sampleText = \"Unicorns can't fly.\"\n",
    "classifier = pipeline(\"sentiment-analysis\", model=loaded_model, tokenizer=tokenizer)\n",
    "\n",
    "preprocess_inference_input = preprocess_text(sampleText)\n",
    "classifier(preprocess_inference_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2fe42-0c03-438a-94c9-1a8bdb593a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
